<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<!-- <meta name="generator" content="./css/jemdoc, see http://jemdoc.jaboc.net/" /> -->
<link rel="stylesheet" type="text/css" href="css/jemdoc.css" />
<!-- <link rel="stylesheet" type="text/css" href="css/stylesheet.css" /> -->
<link rel="stylesheet" type="text/css" href="css/style.css" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<link rel="shortcut icon" href="favicon.ico" />
<link rel="bookmark" href="favicon.ico" type="image/x-icon"　/>
<title>Zijian Wu</title>
</head>
<body>
<table style="background-color: #c5d9e6; padding: 20px 250px;" summary="Table for page layout." id="tlayout">
<tr valign="top">

<td id="layout-content">
<div id="toptitle">
<h1>Zijian Wu </h1>
</div>
<table class="imgtable"><tr><td>
<!-- <a href="https://wuzijian1997.github.io/"><img src="../avatar/dog.jpg" alt="alt text" width="180px" height="180px" /></a>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</td> -->
<!-- <a><img src="../avatar/dog.jpg" alt="alt text" width="180px" height="180px" /></a>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</td> -->
<a><img src="./images/avatar.jpg" alt="alt text" width="130px" height="180px" /></a>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</td>

<td align="left">
<!-- <p>Research Scientist,<br /> -->
<!-- Address: AI Research Institute, Hithink RoyalFlush Information Network Co., Ltd., No. 18 Tongshun Street, Hangzhou City, China <br />  -->
<p style="text-align:justify">I am an incoming Electrical and Computer Engineering Ph.D. student at the University of British Columbia. My advisor is Prof. <a href="https://ece.ubc.ca/tim-salcudean/">Tim Salcudean</a>. Before that, I obtained my Robotics M.S.E. 
  at Johns Hopkins University and B.E. in Mechatronics Engineering at the University of Electronic Science and Technology of China (UESTC), in 2023 and 2020, respectively. I am interested in robotics, medical image analytics and AI for healthcare. My vision is to create a computer-integrated surgical (CIS) system
  enabling robots to perceive special surgical or medical scenarios and to decide rational actions for clinical tasks. I am lucky to work as a Machine Learning Intern at <a href="https://www.moonsurgical.com/">Moon Surgical</a> in 2023 summer. We build things that matter!</p>
E-mail: <a href="mailto:zwu52@jhu.edu">zwu52@jhu.edu</a>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Links: <a href="https://github.com/wuzijian1997">GitHub</a> | <a href="https://wuzijian1997.github.io/">Blog</a> | <a href="pdf/Zijian_Resume_0806.pdf">Resume</a><br />
</td></tr></table>
<!-- <h2>About me</h2>
<p>I received the B.S. degree from the Zhejiang University of Science and Technology, in 2012, and the M.S. degree from Xiamen University, in 2016. I am currently a research scientist with the AI Research Institute, Hithink RoyalFlush, China. My main research interests include Machine Learning, Deep Learning and Recommender Systems. Also, I do some research about Computer Vision, such as knee osteoarthritis prediction, and Time Series Prediction, such as remaining useful life prediction of Lithium-ion batteries. I focus on using AI to solve practical problems.</p> -->
<!-- <h2>Research</h2>
<p>My research interests include: </p>
<ul>
<li><p>Machine Learning  </p>
</li>
<li><p>Deep Learning</p>
</li>
<li><p>Recommender Systems</p>
</li>
<li><p>Computer Vision</p>
</li>
</ul>
<h3>Current work</h3>
<ul>
<li><p>Reinforcement Learning for Knee Osteoarthritis Prediction</p>
</li>
<li><p>Temporal Neural Network for Knee Osteoarthritis Prediction</p>
</li>
<li><p>Expert Neural Network for for Recommendation</p>
</li>
<li><p>Federal Learning for Recommendation</p>
</li>
</ul>
<h3>Under review</h3>
<ol>
<li><p>W. Zhang, Y. Lin, Y. Liu, P. Wu, F. Lin*, and <b>X. Zhou</b>*, "Self-Supervised Reinforcement Learning for Knowledge-aware Recommendation".</p>
</li>
<li><p>Y. Lin, W. Zhang, <b>X. Zhou</b>, F. Lin*, W. Zeng, L. Zou*, Y. Liu, P. Wu, "Knowledge-aware Reasoning with Self-supervised Reinforcement Learning for Explainable Recommendation in MOOCs".</p>
</li> 
<li><p>M. Chen, T. Ma, and <b>X. Zhou</b>*, "CoGraph: Co-occurrence Graph for Recommendation".</p>
</li>
<li><p>M. Chen, and <b>X. Zhou</b>*, "Autoencoders for Drug-Target Interaction Prediction".</p>
</ol> -->

<h2>Publications</h2>
<ol>
<li><p style="text-align:justify"><b>Zijian Wu</b>*, Hamid Moradi*, Shoujue Yang, Hyunwoo Song, Emad M. Boctor, Septimiu E. Salcudean, "Automatic
  Search for Photoacoustic Marker Using Automated Transrectal Ultrasound", <i> Biomedical Optics Express.</i> (Under Review) [<a href="https://arxiv.org/abs/2307.10546">Link</a>]</p>
</li>
<li><p style="text-align:justify">Vincent Vousten*, Hamid Moradi*, <b>Zijian Wu</b>, Emad M. Boctor, Septimiu E. Salcudean, "Laser Diode Photoacoustic
  Point Source Detection: Machine learning-based Denoising and Reconstruction", <i>Optics Express.</i> [<a href="https://opg.optica.org/oe/fulltext.cfm?uri=oe-31-9-13895&id=529041">Link</a>]</p>
</li>
<li><p style="text-align:justify">Roger Soberanis, <b>Zijian Wu</b>, Keith Kleinman, Cody Cross, Brittany-Lee Smith, Mathias Unberath, Therese Canares, "A
  Novel Method to Screen for Urinary Tract Infections with Artificial Intelligence and Smartphone Images", <i>Pediatric
    Academic Societies (PAS) Meeting 2023.</i> (Poster)</p>
</li>
<li><p style="text-align:justify">Hyunwoo Song*, Shuojue Yang*, <b>Zijian Wu</b>, Hamid Moradi, Russell H. Taylor, Jin U. Kang, Septimiu E. Salcudean,
  Emad M. Boctor, "Arc-to-line Frame Registration Method for Ultrasound and Photoacoustic Image-guided Intraoperative
  Robot-assisted Laparoscopic Prostatectomy", <i>IPCAI 2023</i>. <b style="color:red">Best Paper Runner-up</b> [<a href="https://arxiv.org/abs/2306.12590">pdf</a>]</p>
</li>
</ol>
<p><b>Note</b>: * indicates the equal contribution.</p>
<!-- <p><a href="https://scholar.google.com/citations?user=xTzN-qoAAAAJ&amp;hl=zh-CN&amp;oi=ao">Google Scholar</a>.</p> -->

<!-- <h3>Academic service</h3>
<p><b>Reviewer</b></p>
<ul>
<li><p>IEEE Transactions on Industrial Informatics</p>
</li>
<li><p>IEEE Access</p>
</li>
<li><p>ACM Transactions on Knowledge Discovery from Data</p>
</li>  
<li><p>Mathematical Problems in Engineering</p>
</li>
</ul>
<p><a href="https://publons.com/researcher/3034188/xiuze-zhou/">More details in Publons</a></p> -->

<!-- <h2>Selected Projects</h2>
<table
style="
  border: 0px;
  border-spacing: 0px;
  border-collapse: separate;
  padding: 10px;
  margin: auto;
"
frame=void
>
<tbody>
  <tr style="padding: 0px">
    <td style="padding: 0px">

      <table
        style="
          border: 0px;
          border-spacing: 0px;
          border-collapse: separate;
          margin: auto;
        "
      >
        <tbody> -->

          <!-- <tr>
            <td
              class="tdimg"
              style="border: 0; padding: 20px; vertical-align: center"
            >
              <img class = "project-image" src="images/AR_demo.gif" style="height: 175px;" />
            </td>
            <td
              class="tdcontent"
              style="padding: 40px 40px;"
            >
              <p>
                <a
                  href="#"
                >
                  <papertitle
                    >Augmented Mirror for Medical Applications in Orthopedics</papertitle
                  >
                </a>
                <br />
                <li style="text-align:justify">Implemented Augmented Mirrors to help users’ depth judgment by conveying additional information from a non-egocentric perspective, i.e. an Augmented mirror​;
                </li>
                <li style="text-align:justify">Developed the Augmented Mirror package with Unity and deployed it to the HoloLens​;
                </li>
                <li style="text-align:justify">Implemented both Vuforia Multi-target tracking and STTAR tracking with NDI markers;</li>
                </li>
                <li style="text-align:justify">Through a simplified Lego Demo, we were able to demonstrate that users can more accurately place the needle into the target dimples with the help of the Augmented Mirror (i.e., having 2 views) than with a single view.​​</li>

              </p>
              <div class="paper" id="mei2018archetypal">
                <a
                  href="pdf/AugmentedMirrorPoster.pdf"
                  >poster</a
                > &nbsp;&nbsp;&nbsp;&nbsp;
                <a
                  href="https://github.com/raymondzhangzxr/Augmented_Mirror_Demo"
                >code</a
                >
              </div>
            </td>
          </tr> -->

          <!-- <tr>
            <td
              class="tdimg"
              style="border: 0; padding: 20px; vertical-align: center"
            >
              <img class = "project-image" src="images/NeRF_toy.png" style="height: 175px;" />
            </td>
            <td
              class="tdcontent"
              style="padding: 40px 40px;"
            >
              <p>
                <a
                  href="#"
                >
                  <papertitle
                    >Strep AI - a Classification Framework for Streptococcus Infection</papertitle
                  >
                </a>
                <br />
                <li style="text-align:justify">Investigated a Neural Radiance Field (NeRF) based rendering method for throat data augmentation;
                </li>
                <li style="text-align:justify">Developed an ad hoc classification framework with PyTorch for each type of specimen’s data;
                </li>
                <li style="text-align:justify">Proposed an image generation workflow based on diffusion model for data standardization.</li>
                <!-<strong>Jieru Mei</strong>, Chunyu Wang, Wenjun Zeng
                <br />
                <em>ECCV</em>, 2018
                <br /> -->
              <!-- </p>
              <div class="paper" id="mei2018archetypal">
                <a
                  href=""
                  >paper</a
                > &nbsp;&nbsp;&nbsp;&nbsp;
                <a
                  href=""
                >code</a
                >
              </div>
            </td>
          </tr> -->
        

          <!-- <tr>
            <td
              class="tdimg"
              style="border: 0; padding: 20px; vertical-align: center"
            >
              <img class = "project-image" src="images/nerve_registration.png" style="height: 180px;"/>
            </td>
            <td
              class="tdcontent"
              style="padding: 40px 40px;"
            >
              <p>
                <a
                  href="https://ciis.lcsr.jhu.edu/doku.php?id=courses%3A456%3A2022%3Aprojects%3A456-2022-23%3Aproject-23"
                >
                  <papertitle
                    >Photoacoustic Image Based Intro-Operative Surgical Guidance System for da Vinci Surgical Robot</papertitle
                  >
                </a>
                <br />
                <li style="text-align:justify">Integrated the overall system with ROS and implemented the pipeline of endoscope-to-photoacoustic image registration and surgical tool tracking with Python;</li>
                <li style="text-align:justify">Developed a real-time automatic search module with MATLAB for photoacoustic marker’s localization and validated its feasibility by simulation analysis and ex vivo tissue study;</li>
                <li style="text-align:justify">Proposed an arc-line registration algorithm requiring no coordinates in the fluorescence image to boost the time efficiency while maintaining accuracy. </li>
              </p>
              <div class="paper" id="mei2018archetypal">
                <a
                  href=""
                  >paper</a
                > &nbsp;&nbsp;&nbsp;&nbsp;
                <a
                  href=""
                >code</a
                > &nbsp;&nbsp;&nbsp;&nbsp;
                <a
                  href="pdf/Poster_IUS2022_FindingLaserSpot.pdf"
                >poster</a
                >
              </div>
            </td>
          </tr> -->

          <!-- <tr>
            <td
              class="tdimg"
              style="border: 0; padding: 20px; vertical-align: center"
            >
              <img class = "project-image" src="images/SMT.png" style="height: 180px;" />
            </td>
            <td
              class="tdcontent"
              style="padding: 40px 40px;"
            >
              <p>
                <a
                  href="#"
                >
                  <papertitle
                    >Image-based Software System for Surface Mounting Machine</papertitle
                  >
                </a>
                <br />
                <li style="text-align:justify">Developed a robust and user-friendly software system for Surface Mounting Machine to achieve precise
                  positioning, automatic picking, and mounting of electronic components;</li>
                <li style="text-align:justify">Built a prototype of Surface Mounting Machine from scratch;</li>
                <li style="text-align:justify">Improved lighting system and mechanical structure of the prototype.</li>
              </p>
              <div class="paper" id="mei2018archetypal">
              </div>
            </td>
          </tr> -->

          <!-- <tr style="border: 0">
            <td
              class="tdimg"
              style="padding: 40px; vertical-align: center"
            >
              <img class="project-image" src="images/mei2016scriptiden.png" />
            </td>
            <td
              class="tdcontent"
              style="padding: 40px 40px;"
            >
              <p>
                <a
                  href="https://projet.liris.cnrs.fr/imagine/pub/proceedings/ICPR-2016/media/files/0845.pdf"
                >
                  <papertitle
                    >Scene text script identification with convolutional
                    recurrent neural networks</papertitle
                  >
                </a>
                <br />
                <strong>Jieru Mei</strong>, Luo Dai, Baoguang Shi, Xiang
                Bai
                <br />
                <em>ICPR</em>, 2016
                <br />
              </p>
              <div class="paper" id="mei2016scriptiden">
                <a
                  href="https://projet.liris.cnrs.fr/imagine/pub/proceedings/ICPR-2016/media/files/0845.pdf"
                  >paper</a
                >
              </div>
            </td>
          </tr> -->
        <!-- </tbody>
      </table>

      
    </td>
  </tr>
</tbody>
</table> -->

<!-- <ol>
<li><p>Advertising Platform Development, 01.2022-Present</p></li>
<ul>
<li><p>Provide advertising strategies and solutions for advertisers to maximize revenue</p>
</li>
<li><p>Provide automated advertising instead of manual selection</p>
</li>
<li><p>Use users' history information to build their profiles, and then select the target users</p>
</li>
</ul>
<li><p>Campus Recommender System, 03.2021-12.2021</p></li>
<ul>
<li><p>Built user profiles based on the data crawled from websites</p>
</li>
<li><p>Recommended information, such as courses from MOOC, and publications from Arxiv, to students</p>
</li>
<li><p>Recommended information from within and outside the university based on faculty research, courses taught, and interests</p>
</li>
</ul>
<li><p>Online Education Explainable Recommender System, NSFC, 06.2018-12.2018</p></li>
<ul>
<li><p>Summarized over 500,000 exercises and classified their knowledge points from all subjects</p>
</li>
<li><p>Applied matrix factorization for online learning and recommendation of exercises based on interaction of users</p>
</li>
<li><p>Added latent features learned by neural networks from exercises to online matrix factorization for better performance</p>
</li>
</ul>
<li><p>Development of Memorizing Words APP, 06.2017-02.2018</p></li>
<ul>
<li><p>Extracted the records of memorizing words of over 100,000 users from a database</p>
</li>
<li><p>Counted the pairs of error words with the co-occurrence rate to obtain a co-occurrence table</p>
</li>
<li><p>Provided words, along with situation pictures, to enhance memory and showed co-occurrence words from a table</p>
</li>
</ul>
<li><p>Analysis of Film Review from <i>Douban.com</i>, 09.2016-03.2017</p></li>
<ul>
<li><p>Crawled film reviews and ratings from websites</p>
</li>
<li><p>Segmented words and cleaned and processed texts</p>
</li>
<li><p>Added features learned by neural networks to matrix factorization to predict movie's ratings</p>
</li>
</ul>
<li><p>Topics Analysis on <i>Weibo</i>, 05.2015-02.2016</p></li>
<ul>
<li><p>Crawled Weibo messages from websites</p>
</li>
<li><p>Segmented words, cleaned and processed texts, converted the data for storage and analytics</p>
</li>
<li><p>Built a topic model LDA by C<tt></tt> and applied it to obtain topics of Weibo for discovering hot events</p>
</li>
</ul>
<li><p>Email-Based User Relationship Analysis, 10.2014-02.2015</p></li>
<ul>
<li><p>Cleaned and processed the contents of over 100,000 emails to obtain message bodies</p>
</li>
<li><p>Built an author-topic model with biterm pattern by C<tt></tt></p>
</li>
<li><p>Used model to identify relationships between users based on communication contents</p>
</li>
</ul>
<li><p>Smart Home System, 03.2011-02.2012</p></li>
<ul>
<li><p>Designed and built a hardware system including PCB, sensors, and single-chip microcomputer</p>
</li>
<li><p>Developed a program of single-chip microcomputer with language C to realize the function of the system</p>
</li>
<li><p>Developed a human-computer interaction software with C# for signal reception, processing, and transmission</p>
</li>
</ul>
</ol> -->

<h2>Work Experience</h2>
<ul>
  <li>
    <p>Macchine Learning Intern <span style="float: right;">06/2023 ~ present</span></p>
    <a href="https://www.moonsurgical.com/">Moon Surical</a>, with <a href="https://scholar.google.co.uk/citations?user=QtU206AAAAAJ&hl=en">Dr. Menglong Ye</a> <span style="float: right;">San Carlos, CA, U.S.</span>  
  </li>
</ul>
<ul>
  <li>
    <p>Research Intern <span style="float: right;">06/2022 ~ 08/2022</span></p>
    ARCADE Lab, JHU, with Prof. Mathias Unberath <span style="float: right;">Baltimore, MD, U.S.</span>
  </li>
</ul>
<ul>
  <li>
    <p>Research Assistant <span style="float: right;">08/2020 ~ 07/2021</span></p>
    Vision Measuring and Learning Lab, School of Automation Engineering, <a href="https://en.uestc.edu.cn/">UESTC</a> <span style="float: right;">Chengdu, China</span>  
  </li>
</ul>

<h2>Education</h2>
<ul>
<li><p>M.S.E., Robotics, <a href="https://www.jhu.edu/">Johns Hopkins University</a> <span style="float: right;">09/2021 ~ Present</span></p></li>
<!-- <p style="text-align:justify">Main Courses: Algorithms for Sensor-Based Robotics; Robot Devices, Kinematics, Dynamics, and Control; Computer Integrated Surgery I & II; Computer Vision; Augmented Reality; Statistical Learning For Engineers; Vision as Bayesian Inference</Base>.</p> -->
</ul>

<ul>
<li><p>B.E., Mechatronics Engineering, <a href="https://en.uestc.edu.cn/">University of Electronic Science and Technology of China (UESTC)</a> <span style="float: right;">09/2016 ~ 06/2020</span></p></li>
<!-- <p>Main Courses: C Programming; Embedded Systems; Computer Network and Communication; Computer Control System.</p> -->
</ul>
<!-- <h3>Competitions and awards</h3>
<ol>
<li><p>First-Class Scholarship, Zhejiang University of Science and Technology, 10.2011</p>
</li>
<li><p>National Encouragement Scholarship, 12.2011 & 12.2010</p>
</li>
<li><p>The 2nd Prize in the National Advanced Mathematics Contest for Undergraduates (Zhejiang), 12.2011</p>
</li>
<li><p>The 2nd Prize in the Zhejiang Advanced Mathematics Contest for Undergraduates, 04.2011</p>
</li>
<li><p>The 3rd Prize in the Zhejiang Advanced Mathematics Contest for Undergraduates, 10.2009 & 04.2010</p>
</li>
<li><p>The 3rd Prize in the Zhejiang Physics Contest for Undergraduates, 12.2009 & 12.2010</p>
</li>
<li><p>The 1st Prize in the Electronics Design Contests, Zhejiang University of Science and Technology, 12.2010</p>
</li>
</ol>
<h3>Activities</h3>
<ol>
<li><p>Teaching Assistant, Xiamen University, 09.2013-01.2014</p></li>
<ul>
<li><p>Guided freshmen in the subjects of Advanced Mathematics and Programming C and taught some learning skills</p>
</li>
</ul>
<li><p>Assistant Mentor, Zhejiang University of Science and Technology, 09.2010-06.2011</p></li>
<ul>
<li><p>Led freshmen to adapt quickly to their new environment and helped them solve their study problems</p>
</li>
</ul>
<li><p>Journalist, Press Corps of Zhejiang University of Science and Technology, 12.2008-06.2011</p></li>
<ul>
<li><p>Conducted face-to-face interviews, wrote news articles, which received positive audience responses</p>
</li>
</ul>
<li><p>Founder and Editor in Chief, Say Ourselves, E-magazine, 12.2009-08.2011</p></li>
<ul>
<li><p>Created a monthly e-magazine about college life</p>
</li>
</ul>
</ol> -->

<h2>Awards</h2>
<ul>
  <li>
    <p> <a href="images/ipcai_award.jpg">IPCAI 2023 Best Paper Runner-up Award &nbsp</a> <span style="float: right;">06/2023</span></p>
    The 14th International Conference on Information Processing in Computer-Assisted Interventions <span style="float: right;">Munich, Germany</span>  
  </li>
</ul>
<ul>
  <li>
    <p> <a href="https://github.com/raymondzhangzxr/Augmented_Mirror_Demo">Best Demo Award 1st Runner-up &nbsp</a> <span style="float: right;">12/2022</span></p>
    Johns Hopkins University EN.601.654 Augmented Reality Course Project <span style="float: right;">Baltimore, MD, USA</span>  
  </li>
</ul>
<ul>
  <li>
    <p> <a href="https://2019.igem.org/Team:UESTC-China">Golden Award and Nominated Best Hardware Project &nbsp </a> <a href="https://2019.igem.org/Team:UESTC-China"><img src="images/trophy_pixel.svg" height=13px/></a> <span style="float: right;">11/2019</span></p>
    International Genetically Engineered Machine Competition (iGEM) 2019 <span style="float: right;">Boston, MA, USA</span>  
  </li>
</ul>
<ul>
  <li>
    <p> <a href="https://2018.igem.org/Team:UESTC-China">Golden Award and Best Energy Project (1st in Energy Track) </a> &nbsp <a href="https://2018.igem.org/Team:UESTC-China"><img src="images/trophy_pixel.svg" height=13px/></a> <span style="float: right;">10/2018</span></p>
    International Genetically Engineered Machine Competition (iGEM) 2018 <span style="float: right;">Boston, MA, USA</span>
  </li>
</ul>

<!-- <ul>
<li><p>Awards: Principal Level Scholarship (1st in admission)</p>
</li>
<li><p>Main Courses: Algorithms for Sensor-Based Robotics, Robot Devices, Kinematics, Dynamics, and Control, Computer Integrated Surgery I & II, 	Statistical Learning For Engineers, Vision as Bayesian Inference</Base>.</p>
</li>
</ul> -->

<!-- <p><br /> -->
<!-- <a href="cv/cv.pdf">A brief cv</a>.</p>
</td>
</tr>
</table>
</body>
</html>